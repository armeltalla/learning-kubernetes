# 6. Creating a Production-Grade Workflow

## Development Workflow

- Any development flow needs to fit the basic needs of…
- → Development →Testing → Deployment → Repeat

## Flow Specifics

1. Development
    - Create a Github Repo
    - 2 branches: feature branch and master branch
    - Make changes on non-master branch only
    - Push to github
    - Create Pull Request to merge with master
2. Test
    - Code pushed to Travis CI
    - Tests run
    - If tests are passed, merge pull request with master
3. Production
    - Code pushed to Travis CI
    - Tests run
    - Deploy to AWS Elastic Beanstalk

## Docker’s Purpose

- Sooo how does Docker fit into the previous flow specific? (We didn’t mention it at all)
- Docker is a **tool** in a normal development workflow
    - You don’t have to use Docker
    - Docker just makes some of these tasks *a lot easier*

## Project Generation

- We are going to use a project that we didn’t write (pretty much at all)
    - We’re not concerned with the code in the container
    - We’re concerned with how the container is used
- Goes through Node JS implementation (I already had it downloaded)
- In the next lecture, we will be going over how to install Create React App globally and generate the application. This method of generating a React project is no longer recommended.
- **Instead of this:**
    - `npm install -g create-react-app`
    - `create-react-app frontend`
- **We need to run this command:**
    - `npx create-react-app frontend`
- **Documentation:** https://create-react-app.dev/docs/getting-started#npx
- Run `npx create-react-app frontend` in your directory of choice to create the react application

## Necessary Components

- 3 commands you need to remember
    1. `npm run start` - starts up a **development** server 
        - *Development use only*
    2. `npm run test` - runs test associated with the project
    3. `npm run build` - builds a **production** version of the application

## Creating Dev Dockerfile

- We name our development file [Dockerfile.dev](http://Dockerfile.dev) to indicate it is only for development purposes
- Dockerfile.dev
    
    ```docker
    FROM node:16-alpine
    
    WORKDIR '/app'
    
    COPY package.json .
    RUN npm install
    
    COPY . . 
    
    CMD ["npm", "run", "start"]
    ```
    
- To build our Dockerfile.dev, we must tweak our docker build command
    - Use `docker build -f [Dockerfile.dev](http://Dockerfile.dev) .`  to create our image
    - `-f` specifies the file used to build the container
- **Notice our Dockerfile took awhile to build and was 155 MB**
    - our node_modules folder contains a bunch of dependencies (installed by default)
    - Docker includes these in the container —> but we don’t need it!
- Solution: delete node_modules folder (since it is duplicate)
    - This time it builds very quickly

## Starting the Container

- We run our container with `docker run <image-id>`
    - Problem: Can’t use [localhost:3000](http://localhost:3000) —> error
    - Recall —> need to tell the container how to connect the ports
    - We use `docker run -p 3000:3000 <image-id>`
    - Problem solved!

## Docker Volumes

- Goal: we want to be able to edit source code and have it reflect without stopping our local server, rebuilding the container, and starting again
- We do this with docker volumes
    - Essentially has references within created container to the source code locally
- docker volumes are a bit of the pain in the ass
- `docker run -p 3000:3000 -v /app/node_modules -v $(pwd):/app <image-id>`
    - `-v $(pwd):/app` maps our pwd to our /app folder in our container
- What happens without `-v /app/node_modules` ?
    - `docker run -p 3000:3000 -v $(pwd):/app 5941b7c74940` gives Error
    - Error: sh: react-scripts: not found
- What was the problem?
    - We deleted the `node_modules` directory locally
        
        —> the node_modules in the container got overwritten by the reference back to our local directory
        
- Solution: tell it to look in the container (not the reference for the Node modules folder
    - `-v /app/node_modules` - don’t map anything over this or change it; just use this `node_modules`

### ***If the hot reload is not working, downgrade “react-scripts” in package.json to 4.0.3 ([GitHub Issue](https://github.com/facebook/create-react-app/issues/11879#issuecomment-1024535846))***

## Shorthand with Docker Compose

- Instead of `docker run -p 3000:3000 -v /app/node_modules -v $(pwd):/app <image-id>` we make the `docker-compose.yml` file to make things easier

```yaml
version: '3'
services: 
  web: 
    build: . // this causes problems if "Dockerfile" doesn't exist
    ports:
      - "3000:3000"
    volumes: 
      - /app/node_modules
      - .:/app
```

## Overriding Dockerfile Selection

- Instead of `docker run -p 3000:3000 -v /app/node_modules -v $(pwd):/app <image-id>` we make the `docker-compose.yml` file to make things easier

```yaml
version: '3'
services: 
  web: 
    build: 
			context: .    // where the files for the docker container are located
			dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
    volumes: 
      - /app/node_modules
      - .:/app
```

## Do We Need COPY?

- No, we do not necessarily need to COPY the files in this scenario since it is being used in the volume
- However, it is good practice
    - You will likely need to deploy the Dockerfile without using the local volume (production)
    - It’s a good reminder for the future
    - It does not hurt anything. The volume takes precedent so nothing is affected at all

## Executing Tests

- Build: `docker build -f [Dockerfile.dev](http://Dockerfile.dev) -t bensmidt/web .`
- Run Test: `docker run bensmidt/web npm run test`
- The container cannot receive any input at the moment
    - By default the container is connected to output
    - We must use the `-it` flag to use inputs
- `docker run -it bensmidt/web npm run test`

## Live Updating Tests

### Solution 1

- Attach to the existing container
1. Run `docker-compose up`
2. Run `docker run -it <container-id> npm run test`
- This works because our volume mapping is already set up
    - We’re just attaching to this container with the proper volume mapping set up for us
- Not necessarily the best solution → a few steps involved

### Solution 2

- Second service in docker-compose file using volumes
- Change our docker-compose file

```yaml
version: '3'
services: 
  web: 
    build: 
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "3000:3000"
    volumes: 
      - .:/app
      - /app/node_modules
  tests: 
    build: 
      context: .
      dockerfile: Dockerfile.dev
    volumes: 
      - .:/app
      - /app/node_modules
    command: ["npm", "run", "test"]
```

- This creates one container for our application and one container for our tests
- Problem
    - You can only see the tests in the docker-compose output
    - You can’t interact with it like we were able to do before

## Shortcomings on Testing

- Our terminal is not connected to the “tests” service (container)
- docker-compose does not allow use to easily do this
- Attempt
    - `docker attach <container-id>`
    - This should allow us to interact with the container’s terminal as if it were our own
    - This does not work though
- We cannot fix this issue with docker-compose !
- running npm run test does not actually run it as we would think
- The npm command creates a secondary process in the container, which we cannot attach to
- To manipulate the test suites, we must use [Solution 1](https://www.notion.so/Docker-and-Kubernetes-The-Complete-Guide-Stephen-Grider-cefe409e5fa5433e8881c3c02571bd8c?pvs=21) in [Live Updating Tests](https://www.notion.so/Docker-and-Kubernetes-The-Complete-Guide-Stephen-Grider-cefe409e5fa5433e8881c3c02571bd8c?pvs=21)

## Need for Nginx

- `npm run build` is different from `npm run start` or `npm run test`
- `npm run start`
    - We have a development server inside of our container, which is 100% necessary
    - It’s responsible for running the code and allows us to change our code dynamically
- `npm run build`
    - Development does not exist
        - Not appropriate for production → no new changes
    - We need some server with the compiled frontend code to serve browser requests
- We will use `nginx` to solve this production problem
    - We will create a separate `Dockerfile` with `nginx` to do this

## Multi-Step Docker Builds

- First thoughts
    1. Use node:alpine 
    2. Copy package.json file
    3. Install dependencies
    4. Run `npm run build`
    5. Start `nginx` 
- Two big issues
    1. Dependencies only have to be installed because we’re building the application
        - Once application is built, the dependencies are no longer required
        - The dependencies are heavy → don’t want to carry them around if possible
    2. `nginx` isn’t configured at all 
- Problem: we need two base images
- Solution: multi-step build process
    1. Build phase with node:alpine image 
    2. Run phase with `nginx` image
        - Get the build folder from the build phase container and copy it

## Implementing Multi-Step Builds

- New Dockerfile

```docker
# Build phase
FROM node:16-alpine as builder
WORKDIR '/app'
COPY package.json .
RUN npm install
COPY . . 
CMD ["npm", "run", "build"]

# Run phase
FROM nginx
COPY --from=builder /app/build usr/share/nginx/html
# nginx container will start up everything for us
```
